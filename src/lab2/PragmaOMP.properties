#Resumen de Pragmas OpenMP
#pragma omp parallel
Clausulas: 
    num_threads(N)
    if(var-list)
    shared(var-list)
    private(var-list)
    firstprivate(var-list)
    default(none|shared|private|firstprivate)
    threadprivate
    lastprivate(var-list)
    reduction(var-list)
#pragma omp for  - (Do/For) Paralelismo de datos
Clausulas:
    private(var-list)
    shared(var-list)
    lastprivate(var-list)
    firstprivate(var-list)
    reduction(+:sum)
    nowait # se salta la barrera al final del bucle
    collapse # Distribuye el trabajo en bucles anidados
    schedule - Opciones:
        STATIC # chunk (trozos) de igual tamaño
        STATIC, chunk #Se divide en trozos de tamaño N
        DYNAMIC, chunk # se divide de forma automatica, chunk=1 por defecto
        GUIDE, chunk #El tamaño de los trozos se reduce con los hilos
        AUTO
        RUNTIME #usa las variables OMP_SCHEDULE API omp_set_schedule()

#pragma omp sections - para crear secciones de código concurrente entre hilos (Paralelismo funcional)
                    #- Cada sección se distruye en los hilos disponibles, Conllevan barrera implícita
Clausulas:
    private(var-list)
    lastprivate(var-list)
    firstprivate(var-list)
    reduction(+:sum)
    nowait

#pragma omp single - Para expresar una región secuencial dentro de una región paralela (Serializa la sección del codigo)
                  #- Un hilo ejecuta una sección de código, Conlleva un barrier implícito
Clausulas:
    private(var-list)
    firstprivate(var-list)
    nowait
#------------------------------------------#
######## OpenMP Sincronización  ############
#------------------------------------------#
#pragma omp barrier #Pone una barrera, hasta que todos los hilos hayan terminado se puede continuar.
#pragma omp critical #Solo un hilo se ejecuta al tiempo sirve para cuando hay contadores y sumadores para sincronizar los hilos y no se pierda su valor
#pragma omp atomic #más eficiente que critical, no es compatible con critical -> no deberian estar juntas dentro de una region paralela
#pragma omp master# Región paralela, la ejecuta el hilo maestro
cerrojos:
    omp_init_lock: inicialización
    omp_set_lock: adquisición del cerrojo
    omp_unset_lock: devolución del cerrojo
    omp_test_lock: chequeo de si el cerrojo está libre (no bloqueante)
    omp_destroy_lock: libera recursos de cerrojo
#-----------------------------------------#
######## OpenMP Vectorización  ############
#-----------------------------------------#
Automatica # No se hace nada
Guiada #Pragmas
Explicita # 
#pragma omp simd #En ciclos for
#pragma omp for simd #
Clausulas:
    private(var-list)
    reduction(op: var-list)
    safelen(length) #iteraciones en las que no se rompe la dependencia
    linear(list[:linear-step])
    aligned(list[:alignment])
    collapse(n) 
#pragma omp declare simd #En funciones
#pragma omp simd aligned(array) #Se le indica al compilador que alinea la memoria del Array
#pragma omp simd aligned(var1, var2, var3) 
__assume_aligned(array, 64);#mirar reporte si dice unaligned access, ya despues se mejora el speedUp y vector cost 
##pragma omp simd reduction(+:sum) linear(p:step)
#pragma omp declare simd simdlen(16)
uint32_t mandel(fcomplex c)
#------------------------------------------#
############### OpenMP Task  ###############
#------------------------------------------#
Util para explotar paralelismo no-estructurado:
    Bucles sin límites definidos: while ( <expr> ) {...}
    Funciones recursivas
#pragma omp task
clausulas:
    shared
    private
    firstprivate
    default(shared|none)
    in_reduction
    depend(dep-type:list)#Sirve para sincronizar las tareas y crear dependencias entre ellas
#pragma omp task untied #no esta tada al hilo
#pragma omp taskyield #No esta da atada al hilo d ela tarea anterior
#pragma omp taskwait #barrera, espera  a que las demas tareas terminen de ejecutarse
reducciones las dos siguientes
#pragma omp taskgroup task_reduction(+: res)
#pragma omp task in_reduction(+: res)
#pragma omp task detach() # La tarea puede separarse del subproceso en ejecución sin “completarse” Se pueden aplicar


###################################################
###############  GPU ##############
###################################
#pragma omp target  #Envía el bloque al device(kernel, acelarador, la tarjeta grafica), no aprvecha bien el paralelismo es necesario usar mas pragmas
Clausulas:
    device(N)#Indica a cual device quiere envíar la información si solo hay uno no es necesario ponerlo
    map() # Es para cuando las variables son dinamicas si son estaticas no es necesario
	map(to: x) copia del host al device
	map(from: x) trae los datos del device al Host
	map(alloc: x) Reserva espacio en la memoria del device sin copiar los datos
	map(delete: x) Libera espacio del device
	map(release: x) 
    if()#Se puede condicionar cuando ir al device o cuando ir al HOST
#pragma omp target [Enter/exit] data map #reserva espacio en el device
#pragma omp target	update # actualiza los datos con los que hay en el device
Clausulas:
	from()
### Memoria Unificada ###
Se reserva en memoria unificada las variables por lo cual no se hace necesario usar los MAP ni UPDATE ni Enter/Exit
omp.target.malloshared()
omp.target.free
#pragma omp target teams # Crea hilos pero todos los hilos hacen lo mismo
#pragma omp target teams distribute # Este si distribuye el trabajo entre los hilos
#pragma omp target teams distribute parallel for # genera mas hilos que unidades de ejecución lo que oculta latencias , esto es llamado hilos en vuelo

